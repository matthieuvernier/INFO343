{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<h1 align=\"center\">Explorar el concepto de Pluralismo utilizando la Ciencia de los Datos: un estudio de caso con el ecosistema mediático de Chile</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div align=\"center\"><i>Autores: Profesores y Estudiantes del Magíster en Informática (Universidad Austral de Chile)</i></div>\n",
    "<div align=\"center\"><i>I semestre 2018</i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Objetivo de investigación general</h2>\n",
    "<ul>\n",
    "<li><p>El <b>Pluralismo</b> de los medios es un principio que garantiza que l@s ciudadan@s disponen de una información pólitica e ideólogica diversificada, permitiendoles ejercer su <i>espiritu crítico</i> y su <i>libertad de pensar</i>. Por lo tanto, la Organización de las Naciones Unidas para la Educación, la Ciencia y la Cultura (UNESCO) definió el pluralismo de los medios como una condición necesaria para construir la Democracía.</p></li>\n",
    "<li><b>Medir para entender</b>: <i>“When you can measure what you are speaking about, and express it in numbers, you know something about it; but when you cannot measure it, when you cannot express it in numbers, your knowledge is of a meagre and unsatisfactory kind; it may be the beginning of knowledge, but you have scarcely, in your thoughts, advanced to the stage of science, whatever the matter may be.”</i> - Lord Kelvin (1883)\n",
    "<li><b>Pregunta general:</b> ¿La Informática, más particularmente la Ciencia de los Datos, puede medir el Pluralismo de los medios? ¿Se puede establecer un protocolo computacional para medir y entender varias facetas del Pluralismo de los Medios basandose sobre técnicas de Clustering de datos?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Experimentación de Ciencia de los Datos</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>1. Definir una pregunta de investigación </b></h3>\n",
    "\n",
    "<p><u>Ejemplos de preguntas:</u></p>\n",
    "<ul>\n",
    "<li>En el marco de una temática (<i>Mapuche, Cambio climático, Feminismo, Sexismo, etc.</i>), ¿en cuántos tópicos se dividen los discursos de los medios de prensa? ¿Existen diferencias significativas entre los distintos medios? </li>\n",
    "<li>En el marco de una semana de noticias, ¿en cuántos tópicos se dividen las noticias? ¿Existen diferencias significativas entre los distintos medios?</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Recopilar y preparar los datos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Cargar el dataset de tweets\n",
    "df_feminismo = pd.read_csv('datasets/sophia_feminismo.csv',delimiter=\"|\", header=None)\n",
    "df_feminismo\n",
    "\n",
    "#selección de los mensajes\n",
    "docs = df_feminismo[3].as_matrix()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mvernier/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mvernier/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Explorar los datos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109277.498358\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: fisher wars star reciba cooperativa.cl contenido real actriz leia gastronómico copie princesa radio tweet titulares sánchez pst salas maluma contrario ctrl+c noticias inglaterra móvil gratis deportes nicolás tiempos consideremos watson\n",
      "Topic #1: girardi lagos ppd rol helado senador septiembre mal comando amplio campaña ricardo grand jamás intenso xxi navarrete quiere partido ana sexista artístico ex estereotipos cambiar igual específico destacado talla residencia\n",
      "Topic #2: acoso década paz fenómeno casi especies consumidores enrrielar relación maluma estatua protected fono feminazi ¿a lateral león millones casos bienvenidos consiste creen alcaldesa partido meme enfrenta igual sujeto haciéndose entró\n",
      "Topic #3: tweet estados q disney botón venimos trasandina claudia pulsa instantáneamente primero abarca valor funcionó estamos 'la domingo polémicas pareja bestia equipo usuarios esperados ubicación jackson código puntos vecino palabra acto\n",
      "Topic #4: kevin santo vegas spacey septiembre dueñas nuestras extiende cementerio contratos realizaron broma fuertes recuperación reparto estamos rellena nacida trama comedor izquierdista mejorado humano discriminador sentirse dijiste leer stephen detalla típicas\n",
      "Topic #5: internacional laboral fábrica clara beyoncé viral recorrer dar machistas debes femicidio pendiente escribe operar obligan queremos votos pablo tarde queda contundente bachelet villarroel ponía explicación activistas salud documento michelle fin\n",
      "Topic #6: película periféricos cannes significa star transitivo mecanismo tratamiento allá estandarte ideal minorías anuncio ti panelistas guerras existencia pudo filtro común eventos presa asi intentando ningún vasijas cuestión fruto condena supermercado\n",
      "Topic #7: festival madre candidatos pequeña fernanda pololo reconoce casos allí cannes febrero connotación anunciado alrededor cine ríos hora vease titularse pasa profundamente utilizaron trump estados castaldi cinco adecuado estándares cabo música\n",
      "Topic #8: destacado visitas ley plaza equipo piñera pérez difícil viernes ¿ya musulmanes erótica pues empezar pelear puta inaceptable cecilia involucrado estudiaste carlos fundadora carrera surgido impulsos terminé muñoz espinoza siguieron distinto\n",
      "Topic #9: cobren paguen merece- degradarla potencialidades artificiosas sabiéndose pintamos reivindico ministerios cantamos esculturas porcentaje distorsión anulando discoteca prevalecer obligatorias -porque admiro aceptan cuadros vocifera abominable preferencia méritos confrontación quitan comparto- actuando\n",
      "Topic #10: feminismos ciberfeministas radical elquintopoder.cl discurso dedo trump reglas llamados amnistía ganará esas internacional comunidad llaga parecidas existentes materializan ideario podemos agredirla respeto centroizquierda avanzado payaso acción -se creía brazos puesto\n",
      "Topic #11: máxima utilizada llegada preguntas eliminatorias plataforma frase planteando odiar piropo compartida leche familia noche sacaron varios doméstica proporción sarah gobierna derecho glorias producto registrado distinto ocupa miss plantea clásico desafío\n",
      "Topic #12: enero cuatro central utilizan mantenga heavy tradicional inconsciente agobiada perro científica periodista presidencial torres cunas vicuña suárez programa flamante histérico tweet visto incapaces afirmó admitir estudiaste bastante penas trasero inténtalo\n",
      "Topic #13: maravilla película hear n't cine participación mucha sesión administración actriz gadot hijos laboral remunerado pudieron industria habían películas pensiones emma escribir habitual watson civiles guerra modo triunfo plantea personalidades iniciativas\n",
      "Topic #14: actriz protected comenzó anne mí roja incluye comprobado larraín alfombra programa muerte vestidos detalló resultados vestido leí vehículo pues agencia materiales indica trivializa fisher levantaron unió conocida marco próxima esperados\n",
      "Topic #15: tweet web instantáneamente pulsa copiando actualizaciones ubicación añade código desarrolladores tweets infórmate mmm inténtalo retweet enviarlo ¿intentar ubicaciones momentáneo cópiala apasione compartiste instantáneas puntero saturado experimentando únete compartirlo clic pasarás\n",
      "Topic #16: periódico enmarca reestructuración bomba descansará anexo relativos elegidas funerales lacuarta.com nov cuestionada tocan sugerente irrelevante comunicó realizarán firmemente explota bombas mostraba suplemento enfoque verdaderos titulada editoriales exponer cabida erótica regalo\n",
      "Topic #17: hablar séptima directa pelotudo situaría supe feminazis señaló rivas plena vestidos octubre accidente —la caída continuación arriesgar abogado indicaron buscando minas mistral estilo patricia maldonado promoción mirando pasó afectados verano\n",
      "Topic #18: actriz protected programa libro movimiento piñera estamos soy ex feministas amplio candidato serie familia cuerpo campaña agencia parece película mis síguenos estados ley fenómeno acoso universidad libertad foto unidos machista\n",
      "Topic #19: portada atractivo modo ante brutal hacemos pequeña giorgio isla pues true granja tocar méxico cohecho elizabeth personales ambiente aprovechar cierto pdi comunidades taller opcion lema lgtbi ríos labor reggaetón programación\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aplicando Modelos Probabilistas de Tópicos y LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.2, min_df=7,\n",
    "                                stop_words='english',tokenizer=tokenize_only, ngram_range=(1,1))\n",
    "tf = tf_vectorizer.fit_transform(docs)\n",
    "diccionario= tf_vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "#Estimación de LDA con Bayes Variacional\n",
    "lda = LatentDirichletAllocation(n_components=20, max_iter=10,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "#Cálculo de índice de ajuste de los datos\n",
    "print(lda.perplexity(tf))\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "print_top_words(lda, diccionario, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
